There are a couple things you need to be careful about when using the code here.

1. Global variables. Because it's inefficient and annoying to have to read in ~10 variables every time you call a function, a lot of values are stored as global variables. Make sure to take note of what is defined outside of the functions as a global variable and how they are defined as if you want to use this code, you will have to define those global variables. Furthermore, setting the values of some of the global variables is very important: numBins/numJumps determines how precisely your sample will represent the actual data and sampleProportion/significanceLevel will determine how well the function performs when choosing a sample.

2. Converting your data to a usable format. In the multidimensional case, the notebook demonstrates how to convert a sample into usable format by grouping and binning (and provides a function to do so for you). In the one-dimensional case, it reads in functions (for increased accuracy), meaning you will have to generate a pdf for your data. The best way to do this is through kernel density estimation using a kernel with a nice mathematical formula so you can generate the pdfs quickly and easily.

3. You have to do this with a large data set. The whole point of choosing a small data set is that the total amount of data you have is too large to analyze, so you need to take a smaller part of it. The assumption that there's an enormous amount of data is crucial to this algorithm giving a sample that is representative of the population.

4. Choosing a distance metric. I used Hellinger distance: https://en.wikipedia.org/wiki/Hellinger_distance as my distance metric for most of it. However, you can substitute another distance metric, and depending on the situation, having a different distance metric may be preferable. For instance, in the .py file, I used Kolmogorov-Smirnov as it allows us to compute a p-value and compare the algorithm to a random sample. However, for that version, you need to compute cdfs rather than pdfs and Kolmogorov-Smirnov does not scale up to multiple dimensions very well which is why I switched to Hellinger distance.
