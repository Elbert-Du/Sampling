{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Open + read file\n",
    "a = open('multidim-data.txt', 'r')\n",
    "sample = a.readlines()\n",
    "sample = [x.strip('\\n') for x in sample] \n",
    "sample = [x.split(',') for x in sample] \n",
    "\n",
    "#Delete all the attributes you don't care about\n",
    "for i, asdf in enumerate(sample):\n",
    "    del(asdf[7])\n",
    "    del(asdf[0:4])\n",
    "    \n",
    "#Turn strings into floats\n",
    "for i in range(len(sample)):\n",
    "    for j in range(len(sample[i])):\n",
    "        sample[i][j] = float(sample[i][j])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hellinger_dist(sampleDist, PDF):\n",
    "    coefficient = 0\n",
    "    tempDist = copy.deepcopy(sampleDist)\n",
    "    totalSum = np.sum(sampleDist)\n",
    "    for i in indices:\n",
    "        tempDist[i] = tempDist[i] / totalSum\n",
    "    for i in indices:\n",
    "        coefficient += math.sqrt(tempDist[i]*PDF[i])\n",
    "    return math.sqrt(1-coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Recursive helper function to give us all indices so that we can get the values correctly for the multidimensional case.\n",
    "#You should use this to set a global variable before you need to use it so you only need to call this once. If you call this\n",
    "#function many times with many dimensions, it will slow down your code a lot.\n",
    "\n",
    "def nd_range(start, stop, dims):\n",
    "  if not dims:\n",
    "    yield ()\n",
    "    return\n",
    "  for outer in nd_range(start, stop, dims - 1):\n",
    "    for inner in range(start, stop):\n",
    "      yield outer + (inner,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This assumes that your sample is currently an array of arrays, each array corresponding to an element and its elements being the\n",
    "#values of the variables as floats.\n",
    "\n",
    "#you have to define this global variable before you can run the rest of it.\n",
    "numBins = 5\n",
    "    \n",
    "    \n",
    "def sample_to_pdf(sample, numObjects): #sample is the sample that we wish to take a subsample from and numobjects is the number\n",
    "#of groupings we wish to create for the main function.\n",
    "    m = len(sample[0])\n",
    "    n = len(sample)\n",
    "    \n",
    "    #Compute extrema for binning\n",
    "    maxValues = np.zeros((m,))\n",
    "    for i in range(m):\n",
    "        maxValues[i] = -float('inf')\n",
    "    for i in sample:\n",
    "        for j in range(len(i)):\n",
    "            if i[j] > maxValues[j]:\n",
    "                maxValues[j] = i[j]\n",
    "    for i in range(m):\n",
    "        maxValues[i] += 0.0001\n",
    "\n",
    "    minValues = np.zeros((m,))\n",
    "    for i in range(m):\n",
    "        minValues[i] = float('inf')\n",
    "    for i in sample:\n",
    "        for j in range(len(i)):\n",
    "            if i[j] < minValues[j]:\n",
    "                minValues[j] = i[j]\n",
    "    \n",
    "    \n",
    "\n",
    "    binSize = (maxValues - minValues) / numBins\n",
    "    #Create the bins and bin the sample so we get our pdfs as well as the overall pdf.\n",
    "    distributions = np.zeros((numObjects, numBins, numBins, numBins))\n",
    "    overallPDF = np.zeros((numBins, numBins, numBins))\n",
    "    for element in sample:\n",
    "        i = np.random.randint(0,numObjects)\n",
    "        \n",
    "        pos = [0 for i in range(m)]\n",
    "        for j in range(m):\n",
    "            pos[j] = math.floor((element[j]-minValues[j]) / binSize[j])\n",
    "        positions = tuple(pos)\n",
    "        distributions[i][positions]+= 1\n",
    "        overallPDF[positions]+=1\n",
    "    weights = np.zeros((numObjects,))\n",
    "    for i in range(numObjects):\n",
    "        weights[i] = np.sum(distributions[i])\n",
    "    overallPDF = overallPDF / np.sum(overallPDF)\n",
    "    for i, split in enumerate(distributions):\n",
    "        tempSum = np.sum(split)\n",
    "        distributions[i] = split / tempSum\n",
    "    return weights, distributions, overallPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxWeight = 10000\n",
    "sampleProportion = 1/5\n",
    "significanceLevel = 0.9991\n",
    "w, p, overallPDF =sample_to_pdf(sample, 10000)\n",
    "m = 3\n",
    "indices = list(nd_range(0, numBins, m)) #global variable corresponding to all the indices so we only need to generate them once.\n",
    "#It stores everything as tuples and we just call indices to get indices for multidimensional things since nested for loops don't\n",
    "#work with an unknown number of dimensions.\n",
    "def multi_dim_knapsack(w, p, maxWeight):\n",
    "    n = len(w)\n",
    "    m = len(p.shape)-1\n",
    "    totalWeight = 0\n",
    "    currentPDF = np.zeros([numBins for i in range(m)])\n",
    "    contents = dict()\n",
    "    #first, we take a simple random sample that has weight at most maxWeight/2. It should be similar to the population density.\n",
    "    while True:\n",
    "        i = np.random.randint(0,n)\n",
    "        if i not in contents:\n",
    "            if totalWeight + w[i] > maxWeight*sampleProportion:\n",
    "                break\n",
    "            else:\n",
    "                contents[i] = 1\n",
    "                totalWeight += w[i]\n",
    "                totalSum = 0\n",
    "                for k in indices:\n",
    "                    totalSum += p[i][k]\n",
    "                for k in indices:\n",
    "                    currentPDF[k] += w[i]*p[i][k]/totalSum\n",
    "    #Now, we add objects to this sample to try to correct it and make it closer to the population density\n",
    "    \n",
    "    \n",
    "    #This is the approach that adds 1 object at a time. This time, we just take anything that's significantly better\n",
    "    currentDeviation = hellinger_dist(currentPDF, overallPDF)\n",
    "    pairAdded = True\n",
    "    numIts=0\n",
    "    while pairAdded:\n",
    "        counter = 0\n",
    "        for i, weight in enumerate(w):\n",
    "            if i not in contents and totalWeight+w[i] <= maxWeight:\n",
    "                tempPDF = copy.deepcopy(currentPDF)\n",
    "                totalSum = 0\n",
    "                for k in indices:\n",
    "                    totalSum += p[i][k]\n",
    "                for k in indices:\n",
    "                    tempPDF[k] += w[i]*p[i][k]/totalSum\n",
    "                tempDeviation = hellinger_dist(tempPDF, overallPDF)\n",
    "                if tempDeviation <= (significanceLevel)*currentDeviation:\n",
    "                    currentDeviation = tempDeviation\n",
    "                    totalWeight += w[i]\n",
    "                    contents[i] = 1\n",
    "                    currentPDF = tempPDF\n",
    "                    counter += 1\n",
    "                    if totalWeight == maxWeight:\n",
    "                        return contents, currentDeviation, currentPDF, totalWeight, numIts\n",
    "        if counter == 0:\n",
    "            pairAdded = False\n",
    "        numIts += 1\n",
    "    \n",
    "    \n",
    "    return contents, currentDeviation, currentPDF, totalWeight, numIts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b, c, d, e = multi_dim_knapsack(w, p, maxWeight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When running your code on whatever data you are attempting to run this on, the body of the code should look something like this:\n",
    "\n",
    "(define helper functions above)\n",
    "\n",
    "(Read in the data as an array of floats or ints)\n",
    "\n",
    "numBins = k (for a more precise sample, you want to have k as large as possible without making the average number of elements per bin drop too far (ie below 10))\n",
    "\n",
    "maxWeight = 10000\n",
    "\n",
    "sampleProportion = 1/5\n",
    "\n",
    "significanceLevel = 0.9991 (Adjust these 2 parameters manually for best results)\n",
    "\n",
    "w, p, overallPDF =sample_to_pdf(sample, n).     n is just however many groups of elements you wish to create. Fewer -> faster runtime but too few -> we can't fit many objects into the subsample -> we get a bad subsample\n",
    "\n",
    "m = 3\n",
    "\n",
    "indices = list(nd_range(0, numBins, m))\n",
    "\n",
    "a, b, c, d, e = multi_dim_knapsack(w, p, maxWeight)\n",
    "\n",
    "a tells you what groups were used in the subsample, which is what you use for whatever you wanted the subsample for.\n",
    "\n",
    "Finally, a tip about choosing the parameters:\n",
    "\n",
    "You want to leave sampleProportion somewhere about 0.2 and only increase it if you're struggling to fill your subsample.\n",
    "\n",
    "To choose significanceLevel, start off with a pretty high value: generally 0.9 for 100 groups of elements and then decrease the distance to 1 by half every time you multiply the number of groups of elements by 10.\n",
    "\n",
    "Then, you run the algorithm. If the weight of the end result is close to sampleProportion*maxWeight, increase the parameter by a lot. If it's not close to either endpoint, increase it by a little. If the number of iterations (5th variable returned by the function) is 0 or 1, then decrease the parameter by a bit. Repeat this until you get satisfactory results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
