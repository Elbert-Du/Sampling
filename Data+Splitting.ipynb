{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open + read file\n",
    "a = open('multidim-data.txt', 'r')\n",
    "sample = a.readlines()\n",
    "sample = [x.strip('\\n') for x in sample] \n",
    "sample = [x.split(',') for x in sample] \n",
    "\n",
    "#Delete all the attributes you don't care about\n",
    "for i, asdf in enumerate(sample):\n",
    "    del(asdf[7])\n",
    "    del(asdf[0:4])\n",
    "    \n",
    "#Turn strings into floats\n",
    "for i in range(len(sample)):\n",
    "    for j in range(len(sample[i])):\n",
    "        sample[i][j] = float(sample[i][j])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This assumes that your sample is currently an array of arrays, each array corresponding to an element and its elements being the\n",
    "#values of the variables as floats.\n",
    "\n",
    "#you have to define this global variable before you can run the rest of it.\n",
    "numDivs = 5\n",
    "    \n",
    "    \n",
    "def sample_to_pdf(sample, numObjects): #sample is the sample that we wish to take a subsample from and numobjects is the number\n",
    "#of groupings we wish to create for the main function.\n",
    "    m = len(sample[0])\n",
    "    n = len(sample)\n",
    "    \n",
    "    #Compute extrema for binning\n",
    "    maxValues = np.zeros((m,))\n",
    "    for i in range(m):\n",
    "        maxValues[i] = -float('inf')\n",
    "    for i in sample:\n",
    "        for j in range(len(i)):\n",
    "            if i[j] > maxValues[j]:\n",
    "                maxValues[j] = i[j]\n",
    "    for i in range(m):\n",
    "        maxValues[i] += 0.0001\n",
    "\n",
    "    minValues = np.zeros((m,))\n",
    "    for i in range(m):\n",
    "        minValues[i] = float('inf')\n",
    "    for i in sample:\n",
    "        for j in range(len(i)):\n",
    "            if i[j] < minValues[j]:\n",
    "                minValues[j] = i[j]\n",
    "    \n",
    "    \n",
    "\n",
    "    binSize = (maxValues - minValues) / numDivs\n",
    "    #Create the bins and bin the sample so we get our pdfs as well as the overall pdf.\n",
    "    tempList = [numObjects]\n",
    "    tempList.extend([numDivs for i in range(m)])\n",
    "    distributions = list(np.zeros(tempList))\n",
    "    overallPDF = np.zeros([numDivs for i in range(m)])\n",
    "    objectContents = [set() for i in range(numObjects)]\n",
    "    objectDistribution = np.array([1.04**(j) for j in range(numObjects)])\n",
    "    objectDistribution = objectDistribution/sum(objectDistribution)\n",
    "    for k, element in enumerate(sample):\n",
    "        i = np.random.choice(numObjects, p = objectDistribution)\n",
    "        objectContents[i].add(k)\n",
    "        pos = [0 for l in range(m)]\n",
    "        for j in range(m):\n",
    "            pos[j] = math.floor((element[j]-minValues[j]) / binSize[j])\n",
    "        positions = tuple(pos)\n",
    "        distributions[i][positions]+= 1\n",
    "        overallPDF[positions]+=1\n",
    "    weights = list(np.zeros((numObjects,)))\n",
    "    i = 0\n",
    "    numSkipped = 0\n",
    "    while i + numSkipped < numObjects:\n",
    "        weights[i] = np.sum(distributions[i])\n",
    "        if weights[i] == 0:\n",
    "            del(weights[i])\n",
    "            del(distributions[i])\n",
    "            del(objectContents[i])\n",
    "            numSkipped += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    overallPDF = overallPDF / np.sum(overallPDF)\n",
    "    for i, split in enumerate(distributions):\n",
    "        tempSum = np.sum(split)\n",
    "        distributions[i] = split / tempSum\n",
    "    return weights, distributions, overallPDF, objectContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recursive helper function to give us all indices so that we can get the values correctly for the multidimensional case.\n",
    "#You should use this to set a global variable before you need to use it so you only need to call this once. If you call this\n",
    "#function many times with many dimensions, it will slow down your code a lot.\n",
    "\n",
    "def nd_range(start, stop, dims):\n",
    "    if not dims:\n",
    "        yield ()\n",
    "        return\n",
    "    for outer in nd_range(start, stop, dims - 1):\n",
    "        for inner in range(start, stop):\n",
    "            yield outer + (inner,)\n",
    "            \n",
    "def find_depth(List):\n",
    "    if type(List) == list or type(List) == np.ndarray:\n",
    "        return find_depth(List[0]) + 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def hellinger_dist(sampleDist, PDF):\n",
    "    coefficient = 0\n",
    "    tempDist = copy.deepcopy(sampleDist)\n",
    "    totalSum = np.sum(sampleDist)\n",
    "    if totalSum > 0:\n",
    "        for i in indices:\n",
    "            tempDist[i] = tempDist[i] / totalSum\n",
    "        for i in indices:\n",
    "            coefficient += math.sqrt(tempDist[i]*PDF[i])\n",
    "        return math.sqrt(1-coefficient)\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, p, overallPDF, objectContents =sample_to_pdf(sample, 200)\n",
    "maxWeight = 12000\n",
    "m = find_depth(p) - 1\n",
    "indices = list(nd_range(0, numDivs, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.concatenate(p)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple version of the algorithm. The goal is to split a dataset into a number of representative samples such that the sample \n",
    "size is upper bounded by a constant. Furthermore, we want each sample to have a similar number of elements and objects in it.\n",
    "\"\"\"\n",
    "\n",
    "def bin_packing_ffd_mod(weights, pdfs, max_size, distance_func):\n",
    "    avgWeight = sum(weights)/len(weights)\n",
    "    n = len(weights)\n",
    "    sample0 = overallPDF\n",
    "    inds_sorted = np.argsort(weights)[::-1]\n",
    "    #print(inds_sorted)\n",
    "    inds2 = list(inds_sorted)\n",
    "    weights2 = list(weights[inds2[i]] for i in range(n))\n",
    "    pdfs2 = [pdfs[inds2[i]] for i in range(n)]\n",
    "    \n",
    "    bins = [[]]\n",
    "    r_pdfs = [[]]\n",
    "    ind_cur_bin = 0\n",
    "    if weights2[0] > max_size:\n",
    "        return False, []\n",
    "    improves_pdf = True\n",
    "\n",
    "    lower_bound_bins_number = int(round(sum(weights) / max_size + 0.5))\n",
    "    bins = [[x] for x in weights2[:lower_bound_bins_number]]\n",
    "    r_pdfs = [x*weights2[i] for i, x in enumerate(pdfs2[:lower_bound_bins_number])]\n",
    "    indices = [[i] for i in inds2[:lower_bound_bins_number]]\n",
    "\n",
    "    weights2 = weights2[lower_bound_bins_number:]\n",
    "    pdfs2 = pdfs2[lower_bound_bins_number:]\n",
    "    inds2 = inds2[lower_bound_bins_number:]\n",
    "    while weights2:\n",
    "        dispatched = False\n",
    "        cnt = 1\n",
    "        ind_cur_ssample = 0\n",
    "        while not dispatched:\n",
    "            cur_bin = bins[ind_cur_bin]\n",
    "            cur_pdf_bin = r_pdfs[ind_cur_bin]\n",
    "            cur_ind_bin = indices[ind_cur_bin]\n",
    "            \n",
    "            \n",
    "            ks_cur = distance_func(cur_pdf_bin, sample0)\n",
    "            ks_cur2 = distance_func(cur_pdf_bin + weights2[ind_cur_ssample]*pdfs2[ind_cur_ssample], sample0)\n",
    "            # print(sample0.shape, ks_cur, ks_cur2)\n",
    "            #print(cur_bin)\n",
    "            #sum(cur_bin)*np.random.random()/(len(cur_bin)*max_size)\n",
    "            accepted = (len(cur_bin)*sum(cur_bin)*np.random.random()/((n/len(bins))*max_size) < ks_cur2 - ks_cur + 1 - sum(cur_bin)/max_size)\n",
    "            if max_size - sum(cur_bin) >= weights2[ind_cur_ssample] and accepted:\n",
    "                cur_pdf_bin += pdfs2.pop(ind_cur_ssample)*weights2[ind_cur_ssample]\n",
    "                cur_bin.append(weights2.pop(ind_cur_ssample))\n",
    "                cur_ind_bin.append(inds2.pop(ind_cur_ssample))\n",
    "                dispatched = True\n",
    "            elif cnt < 20*len(bins):\n",
    "                cnt += 1\n",
    "                ind_cur_bin = (ind_cur_bin + 1) % len(bins)\n",
    "            else:\n",
    "                if ind_cur_ssample < len(pdfs2) - 1:\n",
    "                    ind_cur_ssample += 1\n",
    "                else:\n",
    "                    print(\"making new bin\")\n",
    "                    cur_bin = []\n",
    "                    cur_pdf_bin = []\n",
    "                    cur_ind_bin = []\n",
    "                    ind_cur_ssample = 0\n",
    "                    cur_pdf_bin += pdfs2.pop(ind_cur_ssample)*weights2[ind_cur_ssample]\n",
    "                    cur_bin.append(weights2.pop(ind_cur_ssample))\n",
    "                    cur_ind_bin.append(inds2.pop(ind_cur_ssample))\n",
    "                    bins.insert(ind_cur_bin, cur_bin)\n",
    "                    r_pdfs.insert(ind_cur_bin, cur_pdf_bin)\n",
    "                    indices.insert(ind_cur_bin, cur_ind_bin)\n",
    "                    dispatched = True\n",
    "    return True, bins, r_pdfs, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b, c, d = bin_packing_ffd_mod(w, p, maxWeight, distance_func=hellinger_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "11722.0\n",
      "8\n",
      "11425.0\n",
      "12\n",
      "11751.0\n",
      "10\n",
      "10969.0\n",
      "13\n",
      "11702.0\n",
      "15\n",
      "11171.0\n",
      "16\n",
      "11709.0\n",
      "11\n",
      "11338.0\n",
      "15\n",
      "11323.0\n",
      "20\n",
      "11222.0\n",
      "17\n",
      "10090.0\n",
      "28\n",
      "10102.0\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "numBins = len(b)\n",
    "print(numBins)\n",
    "totalSum = 0\n",
    "for i in b:\n",
    "    print(sum(i))\n",
    "    print(len(i))\n",
    "    totalSum += sum(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038676722464610125\n",
      "0.034666344497023646\n"
     ]
    }
   ],
   "source": [
    "avgDeviation = 0\n",
    "worstDeviation = 0\n",
    "for i in range(numBins):\n",
    "    x = hellinger_dist(c[i], overallPDF)\n",
    "    avgDeviation += x/(numBins)\n",
    "    if x > worstDeviation:\n",
    "        worstDeviation = x\n",
    "print(worstDeviation)\n",
    "print(avgDeviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,  16,   0,  22,  15,  14,   2,   7,   9,  19,  17,  13,  25,\n",
       "         8,   6,   5,   4,  11,  10,  21,   1,  12,  30,  36,  18,  23,\n",
       "        26,  27,  20,  39,  42,  29,  34,  45,  41,  24,  40,  54,  33,\n",
       "        32,  44,  37,  59,  43,  46,  58,  31,  35,  28,  47,  56,  52,\n",
       "        38,  49,  51,  60,  55,  53,  50,  57,  63,  61,  48,  64,  75,\n",
       "        71,  62,  65,  67,  73,  69,  70,  66,  68,  74,  83,  76,  77,\n",
       "        72,  80,  79,  85,  78,  86,  87,  82,  81,  94,  89,  93,  84,\n",
       "        90,  88,  91,  96,  97,  92,  95,  98, 101, 103, 100, 102, 106,\n",
       "       104,  99, 105, 107, 109, 112, 110, 108, 111, 115, 114, 113, 116,\n",
       "       117, 118, 119, 120, 122, 123, 124, 121, 127, 126, 128, 125, 129,\n",
       "       130, 132, 131, 133, 134, 136, 137, 135, 138, 139, 141, 140, 142,\n",
       "       143, 144, 145, 147, 148, 146, 149, 150, 152, 151, 153, 156, 155,\n",
       "       154, 157, 158, 159, 160, 161, 162, 164, 163, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 179, 181,\n",
       "       182, 183, 184, 185, 186, 187, 189, 188, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.insert(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 5, 3, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(overallPDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This time, we reorder the bins every time we add an object so that the bins are considered in order of increasing weight, making\n",
    "an object more likely to be placed in the bins that are lighter. This makes it so that the weights are more even, but more\n",
    "importantly, that the number of objects in each bin is also about the same. This is because we consider the objects in decreasing\n",
    "order of weight, which means that the objects added close to eachother in the process are also similar in weight, meaning that\n",
    "ordering by weight also roughly orders the samples by the number of objects in them.\n",
    "\"\"\"\n",
    "\n",
    "def bin_packing_ffd_mod2(weights, pdfs, max_size, distance_func):\n",
    "    avgWeight = sum(weights)/len(weights)\n",
    "    n = len(weights)\n",
    "    sample0 = overallPDF\n",
    "    inds_sorted = np.argsort(weights)[::-1]\n",
    "    #print(inds_sorted)\n",
    "    inds2 = list(inds_sorted)\n",
    "    weights2 = list(weights[inds2[i]] for i in range(n))\n",
    "    pdfs2 = [pdfs[inds2[i]] for i in range(n)]\n",
    "    \n",
    "    bins = [[]]\n",
    "    r_pdfs = [[]]\n",
    "    ind_cur_bin = 0\n",
    "    if weights2[0] > max_size:\n",
    "        return False, []\n",
    "    improves_pdf = True\n",
    "\n",
    "    lower_bound_bins_number = int(round(sum(weights) / max_size + 0.5))\n",
    "    bins = [[x] for x in weights2[:lower_bound_bins_number]]\n",
    "    r_pdfs = [x*weights2[i] for i, x in enumerate(pdfs2[:lower_bound_bins_number])]\n",
    "    indices = [[i] for i in inds2[:lower_bound_bins_number]]\n",
    "\n",
    "    weights2 = weights2[lower_bound_bins_number:]\n",
    "    pdfs2 = pdfs2[lower_bound_bins_number:]\n",
    "    inds2 = inds2[lower_bound_bins_number:]\n",
    "    while weights2:\n",
    "        dispatched = False\n",
    "        cnt = 1\n",
    "        ind_cur_ssample = 0\n",
    "        binWeights = [sum(bins[i]) for i in range(len(bins))]\n",
    "        binOrder = np.argsort(binWeights)\n",
    "        cur_bin_num = 0\n",
    "        ind_cur_bin = binOrder[cur_bin_num]\n",
    "        while not dispatched:\n",
    "            cur_bin = bins[ind_cur_bin]\n",
    "            cur_pdf_bin = r_pdfs[ind_cur_bin]\n",
    "            cur_ind_bin = indices[ind_cur_bin]\n",
    "            \n",
    "            \n",
    "            ks_cur = distance_func(cur_pdf_bin, sample0)\n",
    "            ks_cur2 = distance_func(cur_pdf_bin + weights2[ind_cur_ssample]*pdfs2[ind_cur_ssample], sample0)\n",
    "            # print(sample0.shape, ks_cur, ks_cur2)\n",
    "            #print(cur_bin)\n",
    "            #sum(cur_bin)*np.random.random()/(len(cur_bin)*max_size)\n",
    "            accepted = (len(cur_bin)*sum(cur_bin)*np.random.random()/((n/len(bins))*max_size) < ks_cur2 - ks_cur + 1 - sum(cur_bin)/max_size)\n",
    "            if max_size - sum(cur_bin) >= weights2[ind_cur_ssample] and accepted:\n",
    "                cur_pdf_bin += pdfs2.pop(ind_cur_ssample)*weights2[ind_cur_ssample]\n",
    "                cur_bin.append(weights2.pop(ind_cur_ssample))\n",
    "                cur_ind_bin.append(inds2.pop(ind_cur_ssample))\n",
    "                dispatched = True\n",
    "            elif cnt < 10*len(bins):\n",
    "                cnt += 1\n",
    "                cur_bin_num = (cur_bin_num + 1) % len(bins)\n",
    "                ind_cur_bin = binOrder[cur_bin_num]\n",
    "            else:\n",
    "                print(\"making new bin\")\n",
    "                cur_bin = []\n",
    "                cur_pdf_bin = []\n",
    "                cur_ind_bin = []\n",
    "                ind_cur_ssample = 0\n",
    "                cur_pdf_bin += pdfs2.pop(ind_cur_ssample)*weights2[ind_cur_ssample]\n",
    "                cur_bin.append(weights2.pop(ind_cur_ssample))\n",
    "                cur_ind_bin.append(inds2.pop(ind_cur_ssample))\n",
    "                bins.insert(ind_cur_bin, cur_bin)\n",
    "                r_pdfs.insert(ind_cur_bin, cur_pdf_bin)\n",
    "                indices.insert(ind_cur_bin, cur_ind_bin)\n",
    "                dispatched = True\n",
    "    return True, bins, r_pdfs, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a, b, c, d = bin_packing_ffd_mod2(w, p, maxWeight, distance_func=hellinger_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "11178.0\n",
      "18\n",
      "11193.0\n",
      "18\n",
      "11201.0\n",
      "18\n",
      "11204.0\n",
      "15\n",
      "11243.0\n",
      "17\n",
      "11264.0\n",
      "17\n",
      "11189.0\n",
      "17\n",
      "11190.0\n",
      "14\n",
      "11199.0\n",
      "15\n",
      "11272.0\n",
      "15\n",
      "11201.0\n",
      "16\n",
      "11190.0\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "numBins = len(b)\n",
    "print(numBins)\n",
    "totalSum = 0\n",
    "for i in b:\n",
    "    print(sum(i))\n",
    "    print(len(i))\n",
    "    totalSum += sum(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03840824440305688\n",
      "0.034208071516931754\n"
     ]
    }
   ],
   "source": [
    "avgDeviation = 0\n",
    "worstDeviation = 0\n",
    "for i in range(numBins):\n",
    "    x = hellinger_dist(c[i], overallPDF)\n",
    "    avgDeviation += x/(numBins)\n",
    "    if x > worstDeviation:\n",
    "        worstDeviation = x\n",
    "print(worstDeviation)\n",
    "print(avgDeviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As can be seen above, when you reorder the bins every time in order of increasing weights, we can about the same distances from the overall distribution as when we did the FFD bin packing method, but the weights of the bins and the number of objects in the bins is far more similar than with the FFD method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
